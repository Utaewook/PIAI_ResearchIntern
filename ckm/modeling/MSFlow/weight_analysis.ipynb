{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchviz import make_dot\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import default as c\n",
    "from utils import Score_Observer, load_weights, save_weights\n",
    "from models.extractors import build_extractor\n",
    "from models.flow_models import build_msflow_model\n",
    "from datasets import CKMDataset\n",
    "from post_process import post_process\n",
    "from evaluations import eval_det_loc_only\n",
    "from train import train_meta_epoch, inference_meta_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = 'E:\\\\codes\\\\ckm\\\\modeling\\\\MSFlow\\\\work_dirs\\\\msflow_wide_resnet50_2_avgpool_pl258\\\\textile\\\\best_det.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels of extracted features: [256, 512, 1024]\n",
      "Build parallel flows: channels:256, block:2, cond:64\n",
      "Build parallel flows: channels:512, block:5, cond:64\n",
      "Build parallel flows: channels:1024, block:8, cond:64\n",
      "Build fusion flow with channels [256, 512, 1024]\n",
      "Loading weights from E:\\codes\\ckm\\modeling\\MSFlow\\work_dirs\\msflow_wide_resnet50_2_avgpool_pl258\\textile\\best_det.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extractor, output_channels = build_extractor(c)\n",
    "extractor = extractor.to(c.device).eval()\n",
    "parallel_flows, fusion_flow = build_msflow_model(c, output_channels)  # MSFlow 모델 생성\n",
    "parallel_flows = [parallel_flow.to(c.device) for parallel_flow in parallel_flows]\n",
    "fusion_flow = fusion_flow.to(c.device)\n",
    "\n",
    "\n",
    "_ = load_weights(parallel_flows, fusion_flow, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight -> tensor(0.0705, device='cuda:0')\n",
      "bn1.weight -> tensor(0.2466, device='cuda:0')\n",
      "bn1.bias -> tensor(0.2521, device='cuda:0')\n",
      "layer1.0.conv1.weight -> tensor(0.0288, device='cuda:0')\n",
      "layer1.0.bn1.weight -> tensor(0.1395, device='cuda:0')\n",
      "layer1.0.bn1.bias -> tensor(0.0817, device='cuda:0')\n",
      "layer1.0.conv2.weight -> tensor(0.0085, device='cuda:0')\n",
      "layer1.0.bn2.weight -> tensor(0.1161, device='cuda:0')\n",
      "layer1.0.bn2.bias -> tensor(0.1025, device='cuda:0')\n",
      "layer1.0.conv3.weight -> tensor(0.0134, device='cuda:0')\n",
      "layer1.0.bn3.weight -> tensor(0.1279, device='cuda:0')\n",
      "layer1.0.bn3.bias -> tensor(0.0508, device='cuda:0')\n",
      "layer1.0.downsample.0.weight -> tensor(0.0264, device='cuda:0')\n",
      "layer1.0.downsample.1.weight -> tensor(0.1790, device='cuda:0')\n",
      "layer1.0.downsample.1.bias -> tensor(0.0508, device='cuda:0')\n",
      "layer1.1.conv1.weight -> tensor(0.0137, device='cuda:0')\n",
      "layer1.1.bn1.weight -> tensor(0.1319, device='cuda:0')\n",
      "layer1.1.bn1.bias -> tensor(0.0905, device='cuda:0')\n",
      "layer1.1.conv2.weight -> tensor(0.0102, device='cuda:0')\n",
      "layer1.1.bn2.weight -> tensor(0.1346, device='cuda:0')\n",
      "layer1.1.bn2.bias -> tensor(0.0860, device='cuda:0')\n",
      "layer1.1.conv3.weight -> tensor(0.0130, device='cuda:0')\n",
      "layer1.1.bn3.weight -> tensor(0.0739, device='cuda:0')\n",
      "layer1.1.bn3.bias -> tensor(0.0361, device='cuda:0')\n",
      "layer1.2.conv1.weight -> tensor(0.0174, device='cuda:0')\n",
      "layer1.2.bn1.weight -> tensor(0.1493, device='cuda:0')\n",
      "layer1.2.bn1.bias -> tensor(0.0625, device='cuda:0')\n",
      "layer1.2.conv2.weight -> tensor(0.0132, device='cuda:0')\n",
      "layer1.2.bn2.weight -> tensor(0.1553, device='cuda:0')\n",
      "layer1.2.bn2.bias -> tensor(0.0670, device='cuda:0')\n",
      "layer1.2.conv3.weight -> tensor(0.0148, device='cuda:0')\n",
      "layer1.2.bn3.weight -> tensor(0.0921, device='cuda:0')\n",
      "layer1.2.bn3.bias -> tensor(0.0340, device='cuda:0')\n",
      "layer2.0.conv1.weight -> tensor(0.0185, device='cuda:0')\n",
      "layer2.0.bn1.weight -> tensor(0.1514, device='cuda:0')\n",
      "layer2.0.bn1.bias -> tensor(0.0928, device='cuda:0')\n",
      "layer2.0.conv2.weight -> tensor(0.0098, device='cuda:0')\n",
      "layer2.0.bn2.weight -> tensor(0.1685, device='cuda:0')\n",
      "layer2.0.bn2.bias -> tensor(0.0536, device='cuda:0')\n",
      "layer2.0.conv3.weight -> tensor(0.0128, device='cuda:0')\n",
      "layer2.0.bn3.weight -> tensor(0.0998, device='cuda:0')\n",
      "layer2.0.bn3.bias -> tensor(0.0323, device='cuda:0')\n",
      "layer2.0.downsample.0.weight -> tensor(0.0104, device='cuda:0')\n",
      "layer2.0.downsample.1.weight -> tensor(0.0970, device='cuda:0')\n",
      "layer2.0.downsample.1.bias -> tensor(0.0323, device='cuda:0')\n",
      "layer2.1.conv1.weight -> tensor(0.0073, device='cuda:0')\n",
      "layer2.1.bn1.weight -> tensor(0.0877, device='cuda:0')\n",
      "layer2.1.bn1.bias -> tensor(0.0510, device='cuda:0')\n",
      "layer2.1.conv2.weight -> tensor(0.0056, device='cuda:0')\n",
      "layer2.1.bn2.weight -> tensor(0.1040, device='cuda:0')\n",
      "layer2.1.bn2.bias -> tensor(0.0549, device='cuda:0')\n",
      "layer2.1.conv3.weight -> tensor(0.0066, device='cuda:0')\n",
      "layer2.1.bn3.weight -> tensor(0.0655, device='cuda:0')\n",
      "layer2.1.bn3.bias -> tensor(0.0367, device='cuda:0')\n",
      "layer2.2.conv1.weight -> tensor(0.0114, device='cuda:0')\n",
      "layer2.2.bn1.weight -> tensor(0.1260, device='cuda:0')\n",
      "layer2.2.bn1.bias -> tensor(0.0599, device='cuda:0')\n",
      "layer2.2.conv2.weight -> tensor(0.0085, device='cuda:0')\n",
      "layer2.2.bn2.weight -> tensor(0.1468, device='cuda:0')\n",
      "layer2.2.bn2.bias -> tensor(0.0746, device='cuda:0')\n",
      "layer2.2.conv3.weight -> tensor(0.0120, device='cuda:0')\n",
      "layer2.2.bn3.weight -> tensor(0.0821, device='cuda:0')\n",
      "layer2.2.bn3.bias -> tensor(0.0558, device='cuda:0')\n",
      "layer2.3.conv1.weight -> tensor(0.0124, device='cuda:0')\n",
      "layer2.3.bn1.weight -> tensor(0.1234, device='cuda:0')\n",
      "layer2.3.bn1.bias -> tensor(0.0707, device='cuda:0')\n",
      "layer2.3.conv2.weight -> tensor(0.0089, device='cuda:0')\n",
      "layer2.3.bn2.weight -> tensor(0.1414, device='cuda:0')\n",
      "layer2.3.bn2.bias -> tensor(0.0883, device='cuda:0')\n",
      "layer2.3.conv3.weight -> tensor(0.0110, device='cuda:0')\n",
      "layer2.3.bn3.weight -> tensor(0.0737, device='cuda:0')\n",
      "layer2.3.bn3.bias -> tensor(0.0593, device='cuda:0')\n",
      "layer3.0.conv1.weight -> tensor(0.0159, device='cuda:0')\n",
      "layer3.0.bn1.weight -> tensor(0.1704, device='cuda:0')\n",
      "layer3.0.bn1.bias -> tensor(0.1251, device='cuda:0')\n",
      "layer3.0.conv2.weight -> tensor(0.0074, device='cuda:0')\n",
      "layer3.0.bn2.weight -> tensor(0.1461, device='cuda:0')\n",
      "layer3.0.bn2.bias -> tensor(0.0537, device='cuda:0')\n",
      "layer3.0.conv3.weight -> tensor(0.0110, device='cuda:0')\n",
      "layer3.0.bn3.weight -> tensor(0.1226, device='cuda:0')\n",
      "layer3.0.bn3.bias -> tensor(0.0250, device='cuda:0')\n",
      "layer3.0.downsample.0.weight -> tensor(0.0082, device='cuda:0')\n",
      "layer3.0.downsample.1.weight -> tensor(0.0772, device='cuda:0')\n",
      "layer3.0.downsample.1.bias -> tensor(0.0250, device='cuda:0')\n",
      "layer3.1.conv1.weight -> tensor(0.0056, device='cuda:0')\n",
      "layer3.1.bn1.weight -> tensor(0.0883, device='cuda:0')\n",
      "layer3.1.bn1.bias -> tensor(0.0438, device='cuda:0')\n",
      "layer3.1.conv2.weight -> tensor(0.0048, device='cuda:0')\n",
      "layer3.1.bn2.weight -> tensor(0.1180, device='cuda:0')\n",
      "layer3.1.bn2.bias -> tensor(0.0711, device='cuda:0')\n",
      "layer3.1.conv3.weight -> tensor(0.0077, device='cuda:0')\n",
      "layer3.1.bn3.weight -> tensor(0.0712, device='cuda:0')\n",
      "layer3.1.bn3.bias -> tensor(0.0448, device='cuda:0')\n",
      "layer3.2.conv1.weight -> tensor(0.0081, device='cuda:0')\n",
      "layer3.2.bn1.weight -> tensor(0.1182, device='cuda:0')\n",
      "layer3.2.bn1.bias -> tensor(0.0638, device='cuda:0')\n",
      "layer3.2.conv2.weight -> tensor(0.0060, device='cuda:0')\n",
      "layer3.2.bn2.weight -> tensor(0.1313, device='cuda:0')\n",
      "layer3.2.bn2.bias -> tensor(0.0806, device='cuda:0')\n",
      "layer3.2.conv3.weight -> tensor(0.0089, device='cuda:0')\n",
      "layer3.2.bn3.weight -> tensor(0.0741, device='cuda:0')\n",
      "layer3.2.bn3.bias -> tensor(0.0609, device='cuda:0')\n",
      "layer3.3.conv1.weight -> tensor(0.0082, device='cuda:0')\n",
      "layer3.3.bn1.weight -> tensor(0.1100, device='cuda:0')\n",
      "layer3.3.bn1.bias -> tensor(0.0735, device='cuda:0')\n",
      "layer3.3.conv2.weight -> tensor(0.0058, device='cuda:0')\n",
      "layer3.3.bn2.weight -> tensor(0.1199, device='cuda:0')\n",
      "layer3.3.bn2.bias -> tensor(0.0828, device='cuda:0')\n",
      "layer3.3.conv3.weight -> tensor(0.0076, device='cuda:0')\n",
      "layer3.3.bn3.weight -> tensor(0.0671, device='cuda:0')\n",
      "layer3.3.bn3.bias -> tensor(0.0466, device='cuda:0')\n",
      "layer3.4.conv1.weight -> tensor(0.0091, device='cuda:0')\n",
      "layer3.4.bn1.weight -> tensor(0.1152, device='cuda:0')\n",
      "layer3.4.bn1.bias -> tensor(0.0900, device='cuda:0')\n",
      "layer3.4.conv2.weight -> tensor(0.0060, device='cuda:0')\n",
      "layer3.4.bn2.weight -> tensor(0.1232, device='cuda:0')\n",
      "layer3.4.bn2.bias -> tensor(0.0871, device='cuda:0')\n",
      "layer3.4.conv3.weight -> tensor(0.0075, device='cuda:0')\n",
      "layer3.4.bn3.weight -> tensor(0.0709, device='cuda:0')\n",
      "layer3.4.bn3.bias -> tensor(0.0624, device='cuda:0')\n",
      "layer3.5.conv1.weight -> tensor(0.0102, device='cuda:0')\n",
      "layer3.5.bn1.weight -> tensor(0.1263, device='cuda:0')\n",
      "layer3.5.bn1.bias -> tensor(0.1136, device='cuda:0')\n",
      "layer3.5.conv2.weight -> tensor(0.0060, device='cuda:0')\n",
      "layer3.5.bn2.weight -> tensor(0.1305, device='cuda:0')\n",
      "layer3.5.bn2.bias -> tensor(0.0978, device='cuda:0')\n",
      "layer3.5.conv3.weight -> tensor(0.0083, device='cuda:0')\n",
      "layer3.5.bn3.weight -> tensor(0.0734, device='cuda:0')\n",
      "layer3.5.bn3.bias -> tensor(0.0716, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "data = {'name':[],\n",
    "        'weight':[]}\n",
    "\n",
    "\n",
    "for name, param in extractor.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,'->', param.data.abs().mean())\n",
    "        data['name'].append(name)\n",
    "        data['weight'].append(param.data.abs().mean().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv1.weight</td>\n",
       "      <td>0.07052137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bn1.weight</td>\n",
       "      <td>0.24656987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bn1.bias</td>\n",
       "      <td>0.25208694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer1.0.conv1.weight</td>\n",
       "      <td>0.02882829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer1.0.bn1.weight</td>\n",
       "      <td>0.13946417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>layer3.5.bn2.weight</td>\n",
       "      <td>0.13051416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>layer3.5.bn2.bias</td>\n",
       "      <td>0.09781123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>layer3.5.conv3.weight</td>\n",
       "      <td>0.008329967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>layer3.5.bn3.weight</td>\n",
       "      <td>0.07343365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>layer3.5.bn3.bias</td>\n",
       "      <td>0.07155378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name       weight\n",
       "0             conv1.weight   0.07052137\n",
       "1               bn1.weight   0.24656987\n",
       "2                 bn1.bias   0.25208694\n",
       "3    layer1.0.conv1.weight   0.02882829\n",
       "4      layer1.0.bn1.weight   0.13946417\n",
       "..                     ...          ...\n",
       "124    layer3.5.bn2.weight   0.13051416\n",
       "125      layer3.5.bn2.bias   0.09781123\n",
       "126  layer3.5.conv3.weight  0.008329967\n",
       "127    layer3.5.bn3.weight   0.07343365\n",
       "128      layer3.5.bn3.bias   0.07155378\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data, columns=['name', 'weight'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bn1.bias</td>\n",
       "      <td>0.25208694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bn1.weight</td>\n",
       "      <td>0.24656987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>layer1.0.downsample.1.weight</td>\n",
       "      <td>0.179041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>layer3.0.bn1.weight</td>\n",
       "      <td>0.17038327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>layer2.0.bn2.weight</td>\n",
       "      <td>0.16845101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>layer1.2.bn2.weight</td>\n",
       "      <td>0.15533565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>layer2.0.bn1.weight</td>\n",
       "      <td>0.15139613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>layer1.2.bn1.weight</td>\n",
       "      <td>0.14925739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>layer2.2.bn2.weight</td>\n",
       "      <td>0.14684612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>layer3.0.bn2.weight</td>\n",
       "      <td>0.14608306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name      weight\n",
       "2                       bn1.bias  0.25208694\n",
       "1                     bn1.weight  0.24656987\n",
       "13  layer1.0.downsample.1.weight    0.179041\n",
       "73           layer3.0.bn1.weight  0.17038327\n",
       "37           layer2.0.bn2.weight  0.16845101\n",
       "28           layer1.2.bn2.weight  0.15533565\n",
       "34           layer2.0.bn1.weight  0.15139613\n",
       "25           layer1.2.bn1.weight  0.14925739\n",
       "58           layer2.2.bn2.weight  0.14684612\n",
       "76           layer3.0.bn2.weight  0.14608306"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Image.open('E:\\\\codes\\\\ckm\\\\modeling\\\\MSFlow\\\\data\\\\CKM\\\\test\\\\bad\\\\1_3.png').convert('RGB')\n",
    "\n",
    "transform_x = T.Compose([\n",
    "        T.Resize(c.input_size, InterpolationMode.LANCZOS),\n",
    "        T.ToTensor()])\n",
    "normalize = T.Compose([T.Normalize(c.img_mean, c.img_std)])\n",
    "\n",
    "x = normalize(transform_x(x))\n",
    "y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 128, 128])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Only 2D, 3D, 4D, 5D padding with non-constant padding are supported for now",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\codes\\ckm\\modeling\\MSFlow\\weight_analysis.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/codes/ckm/modeling/MSFlow/weight_analysis.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(c\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/codes/ckm/modeling/MSFlow/weight_analysis.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/codes/ckm/modeling/MSFlow/weight_analysis.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m h_list \u001b[39m=\u001b[39m extractor(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/codes/ckm/modeling/MSFlow/weight_analysis.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m h_list:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/codes/ckm/modeling/MSFlow/weight_analysis.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     make_dot(h)\u001b[39m.\u001b[39mview()\n",
      "File \u001b[1;32mc:\\Users\\piai\\anaconda3\\envs\\msflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\piai\\anaconda3\\envs\\msflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\codes\\ckm\\modeling\\MSFlow\\models\\resnet\\resnet.py:245\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32me:\\codes\\ckm\\modeling\\MSFlow\\models\\resnet\\resnet.py:229\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    228\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m    230\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m    231\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\piai\\anaconda3\\envs\\msflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\piai\\anaconda3\\envs\\msflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piai\\anaconda3\\envs\\msflow_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\piai\\anaconda3\\envs\\msflow_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_conv_forward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001b[0;32m    452\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m         \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39;49mpad(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_mode),\n\u001b[0;32m    454\u001b[0m                         weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                         _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Only 2D, 3D, 4D, 5D padding with non-constant padding are supported for now"
     ]
    }
   ],
   "source": [
    "x = x.to(c.device).unsqueeze(0)\n",
    "h_list = extractor(x)\n",
    "\n",
    "for h in h_list:\n",
    "    make_dot(h).view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
